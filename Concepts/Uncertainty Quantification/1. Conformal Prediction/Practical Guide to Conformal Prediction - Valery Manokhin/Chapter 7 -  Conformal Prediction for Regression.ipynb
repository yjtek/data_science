{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 7: Conformal Prediction for Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CP for regression produces prediction **intervals**, as opposed to prediction sets for classification, but the idea is remarkably similar "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is a prediction interval the same as a confidence interval?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Confidence interval:\n",
    "    - What is the uncertainty in your parameter estimate based on a sample statistic? \n",
    "    - It is an aggregate level parameter uncertainty that exists because you only have a sample of data\n",
    "\n",
    "- Prediction interval:\n",
    "    - What is the uncertainty in **this** specific prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Components of a prediction interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Similar to classification:\n",
    "    - Lower/Upper bounds\n",
    "    - Coverage probability (i.e. confidence level) \n",
    "        - 90%/95%/99%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring uncertainty in regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use confidence interval directly\n",
    "    - Compute confidence interval in the dataset\n",
    "    - Add/subtract a fixed value from your point prediction\n",
    "\n",
    "- Resampling methods\n",
    "    - Repeatedly resample a training set from your dataset excluding the specific test sample\n",
    "    - Train a model on the sampled training set, and use it to form a prediction for the test sample\n",
    "    - Use the min/max of these prediction to get a distribution of predictions as the \"prediction interval\"\n",
    "\n",
    "- Bayesian methods\n",
    "    - Use bayesian methods to estimate the posterior distribution of the underlying model\n",
    "    - Since the underlying model parameters has some distribution, naturally its predictions also follow some distribution\n",
    "\n",
    "- Monte Carlo methods\n",
    "    - Similar to resampling, but instead of choosing observations from all available observations, it goes one level deeper to resample from each input variable\n",
    "    - Having reconstructed the training set this way, we can then run the regression again to get a predicted value for the unknown observation\n",
    "\n",
    "- Sensitivity analysis\n",
    "    - Adjust input values to determine how the prediction changes for an unknown observation\n",
    "\n",
    "\n",
    "- Comparing methods and their features\n",
    "    - Marginal Validty: Do we need to assume anything about the distribution of errors/parameters?\n",
    "    - Scalability: Are we able to apply this to large datasets\n",
    "    - Domain Knowledge: Do we need knowledge of the specific problem domain?\n",
    "    - Validation set: Is a separate validation set necessary?\n",
    "\n",
    "| Method | Marginal Validity | Scalability | Domain Knowledge | Validation Set |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| Bayesian Methods (Gaussian process and approximate GP) | No | Only with approximate inference | Yes | No |\n",
    "| Ensemble Methods (Dropout ensemble, deep ensembles, and mean-variance estimator) | No | Yes if scalable models are used | No | No |\n",
    "| Direct Interval Estimation (Neural network quantile regression) | No | Yes | No | Yes |\n",
    "| Conformal Prediction (Neural networks and random forest) | Yes | Yes (For ICP) | No | Yes |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practical: ICP for Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://github.com/PacktPublishing/Practical-Guide-to-Applied-Conformal-Prediction/blob/main/Chapter_07.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import AnnotationBbox, TextArea\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import openml\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "from yellowbrick.regressor import PredictionError\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from crepes.extras import binning\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.model_selection import KFold, RandomizedSearchCV, train_test_split\n",
    "\n",
    "from mapie.metrics import regression_coverage_score, regression_mean_width_score\n",
    "from mapie.regression import MapieQuantileRegressor, MapieRegressor\n",
    "from mapie.subsample import Subsample\n",
    "\n",
    "from crepes import WrapRegressor\n",
    "from crepes.extras import DifficultyEstimator\n",
    "\n",
    "random_state = 23\n",
    "rng = np.random.default_rng(random_state)\n",
    "round_to = 3\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# California housing dataset https://www.openml.org/search?type=data&status=active&id=43939\n",
    "dataset = openml.datasets.get_dataset(43939)\n",
    "\n",
    "# Print a summary\n",
    "print(\n",
    "    f\"This is dataset '{dataset.name}', the target feature is \"\n",
    "    f\"'{dataset.default_target_attribute}'\"\n",
    ")\n",
    "print(f\"URL: {dataset.url}\")\n",
    "print(dataset.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openml API\n",
    "X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "    dataset_format=\"array\", target=dataset.default_target_attribute\n",
    ")\n",
    "df = pd.DataFrame(X, columns=attribute_names)\n",
    "df[\"class\"] = y\n",
    "\n",
    "df['ocean_proximity'] = df['ocean_proximity'].astype('category')\n",
    "df.dropna(subset=['total_bedrooms'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('class', axis = 1)\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inductive Conformal Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1000, shuffle = True, random_state=42)\n",
    "X_proper_train, X_cal, y_proper_train, y_cal = train_test_split(X_train, y_train, test_size=1000)\n",
    "print('Data split. Parts sizes: train = {}, calib = {}, test = {}'.format(X_proper_train.shape, X_cal.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comparing methods for generating prediction intervals for regression (https://arxiv.org/abs/2107.00363)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science-SgH_SThs-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
